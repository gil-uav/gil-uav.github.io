<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="GPS-Independent Localization for UAVs">
	<meta property="og:title" content="Pytorch(v>=1.6.0) performance tuning tips" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gil-uav.github.io////semantic_segmentation/2020/09/23/Pytorch-Optimizations/" />
<meta property="og:image" content="https://gil-uav.github.io///img/home-bg-2.jpg">
	
	

	<meta name="citation_title" content="Project Pages - An Integrated Scientific Blogging Template">


<meta name="citation_author" content="Vegard Bergsvik Øvstegård">



	

	<link rel='shortcut icon' type='image/png' href='/favicon.png' />

    <title>Pytorch(v>=1.6.0) performance tuning tips - GIL-UAV</title>

    <link rel="canonical" href="https://gil-uav.github.io//semantic_segmentation/2020/09/23/Pytorch-Optimizations/">
	
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/clean-blog.css">
	
	<!-- Adjust Colors -->
    <link rel="stylesheet" href="https://gil-uav.github.io//colorscheme.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/syntax.css">

    <!-- Custom Fonts -->
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
	<!-- Math Jax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script type="text/javascript"
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		TeX: { equationNumbers: { autoNumber: "AMS" } }
	});
	</script>

	<!--<script src="http://cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3.min.js" type="text/javascript"></script>-->

    <!-- jQuery -->
	<script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>

	<!-- Bootstrap Core JavaScript -->
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

	<!-- Custom Theme JavaScript -->
	<script src="https://gil-uav.github.io//js/clean-blog.min.js "></script>
	
	
<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100795269-2', 'auto');
  ga('send', 'pageview');

</script>

	
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>
</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">GIL-UAV</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
				
                <li>
                    <a href="/projects/mcl/">Monte Carlo Localization</a>
                </li>
                
                <li>
                    <a href="/projects/semantic_segmentation/">Semantic segmentation</a>
                </li>
                
                
                <li>
                    <a href="/about/">About</a>
                </li>
                
                <li>
                    <a href="/search/">Search</a>
                </li>
                
                <li>
                    <a href="/members/">Members</a>
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/home-bg-2.jpg');">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading" style="padding: 30px 0">
                    <h1>Pytorch(v>=1.6.0) performance tuning tips</h1>
                    
                    <h2 class="subheading">Simple techniques to improve training performance</h2>
                    
                    <span class="meta">Posted by Vegard Bergsvik Øvstegård on September 23, 2020</span>	
                </div>
            </div>
        </div>
    </div>
</header>






	
	
	
	<div class="float-left">
	<div class="recentpost" style="padding: 10px">
	
	<h4> Recently by the same author: </h4> 
	
	<hr class="style-one">
	
	<a href="/2021/01/29/Fourth-Presentation/"><h2 class="post-title"> Fifth progress presentation</h2></a>
	
	
		<h4 class="post-subtitle">Brief presentation of current progress.</h4>
	
	
	<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on January 29, 2021</p>
	
	<div class="notepad-index-post-tags" style="">
	<a href="/search/index.html#presentation" title="Other posts from the Presentation tag">Presentation</a>
	</div> 
	
			
 

<hr class="style-one">

	<img src="/img/profile.jpg" style="margin-top:0px; margin-bottom:5px; margin:auto; width:120px !important; border-radius: 50%;">
	
	<h3>Vegard Bergsvik Øvstegård</h3>
	
	<h4>Master Student at University of Oslo's Department of Informatics</h4>
	
	 
	<a href="https://github.com/vegovs" title="Github"><img src="/img/icons/github-icon.png " style="height:50px; float:right; margin-bot:10px"></a>
	
	
	
	<a href="https://ovstegard.no/" title="Google Plus"><img src="/img/icons/url-icon.png " style="height:33px; float:right; margin-top:9px;  margin-right: 10px"></a>
	
	


	
	</div>
	</div>
	
	
	
	
		
	

<!-- Also Interesting -->



	
	
	

	
	 
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
	

	
	 
	
	
		 
		
		<div class="float-right">
		<div class="relevantpost" style="padding: 10px">
		
		
		<h4> You may find interesting: </h4> 
		
		<hr class="style-one">
		
		<a href="/semantic_segmentation/2020/11/11/Dataset-V2/"><h2 class="post-title"> The dataset v0.1.0</h2></a>
		
		
			<h4 class="post-subtitle">Results from dataset v0.0.1 and a bump to v0.1.0</h4>
		
		
		<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on November 11, 2020</p>
		
		<div class="notepad-index-post-tags" style="">
		<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
		</div> 
		
		
		
		
	
			
		
		 
		
		<hr class="style-one">
		
		<a href="/semantic_segmentation/2020/11/11/Dataset-V2/"><h2 class="post-title"> The dataset v0.1.0</h2></a>
		
		
			<h4 class="post-subtitle">Results from dataset v0.0.1 and a bump to v0.1.0</h4>
		
		
		<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on November 11, 2020</p>
		
		<div class="notepad-index-post-tags" style="">
		<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
		</div> 
		
		
		
		
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
	

	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
	


		</div>
		</div>

<!-- Post Content -->
<style>
img {
	display:block;
	max-width:  100%;
	margin-left: auto;
	margin-right: auto;
}

@media only screen and (min-width: 1000px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(1.2); 
	-webkit-transform:scale(1.2);
	-o-transform:scale(1.2);
}
}

@media only screen and (min-width: 1250px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(1.5); 
	-webkit-transform:scale(1.5);
	-o-transform:scale(1.5);
}
}

@media only screen and (min-width: 1500px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(2); 
	-webkit-transform:scale(2);
	-o-transform:scale(2);
}
}
</style>

<article>
    <div id="content" class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<h1 id="enable-asynchronous-data-loading-augmentation">
Enable asynchronous data loading &amp; augmentation
</h1>
<p>
PyTorch DataLoader supports asynchronous data loading/augmentation. The defaults settings are with 0 threads and no pinned memory. Use num_workers &gt; 0 to enable asynchronous data processing, and it’s almost always better to use pinned memory.
</p>
<p>
Default settings:
</p>
<div id="cb1" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1">DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>, sampler<span class="op">=</span><span class="va">None</span>,</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">           batch_sampler<span class="op">=</span><span class="va">None</span>, num_workers<span class="op">=</span><span class="dv">0</span>, collate_fn<span class="op">=</span><span class="va">None</span>,</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">           pin_memory<span class="op">=</span><span class="va">False</span>, drop_last<span class="op">=</span><span class="va">False</span>, timeout<span class="op">=</span><span class="dv">0</span>,</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">       worker_init_fn<span class="op">=</span><span class="va">None</span>)</a></code></pre>
</div>
<p>
This is faster.
</p>
<div id="cb2" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1">DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>, sampler<span class="op">=</span><span class="va">None</span>,</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">           batch_sampler<span class="op">=</span><span class="va">None</span>, num_workers<span class="op">=</span><span class="dv">8</span>, collate_fn<span class="op">=</span><span class="va">None</span>,</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">           pin_memory<span class="op">=</span><span class="va">True</span>, drop_last<span class="op">=</span><span class="va">False</span>, timeout<span class="op">=</span><span class="dv">0</span>,</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">       worker_init_fn<span class="op">=</span><span class="va">None</span>)</a></code></pre>
</div>
<p>
You know how sometimes your GPU memory shows that it’s full but you’re pretty sure that your model isn’t using that much? That overhead is called pinned memory. ie: this memory has been reserved as a type of “working allocation.” When you enable pinned_memory in a DataLoader it automatically puts the fetched data Tensors in pinned memory, and enables faster data transfer to CUDA-enabled GPUs.
</p>
<figure>
<img src="/img/pinned_memory.png" alt="Pinned memory" />
<figcaption>
Pinned memory
</figcaption>
</figure>
<h1 id="enable-cudnn-autotuner">
Enable cuDNN autotuner
</h1>
<p>
For convolutional neural networks, enable cuDNN autotuner by setting:
</p>
<div id="cb3" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1">torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">True</span></a></code></pre>
</div>
<p>
cuDNN supports many algorithms to compute convolution, and the autotuner runs a short benchmark and selects the algorithm with the best performance.
</p>
<h1 id="increase-batch-size">
Increase batch size
</h1>
<p>
Often <a href="https://pytorch.org/docs/stable/amp.html">AMP</a> reduces memory requirements due to half float precision utilization. Thus increase the batch size to max out GPU memory.
</p>
<p>
When increasing batch size: * Tune the learning rate * Add learning rate warmup and learning rate decay * Tune weight decay or switch to optimizer designed for large-batch training * LARS * LAMB * NVLAMB * NovoGrad
</p>
<h1 id="disable-bias-for-convolutions-directly-followed-by-a-batch-norm.">
Disable bias for convolutions directly followed by a batch norm.
</h1>
<figure>
<img src="/img/bias_conv.png" alt="Disable bias" />
<figcaption>
Disable bias
</figcaption>
</figure>
<h1 id="use-parameter.grad-none-instead-of-model.zero_grad">
Use parameter.grad = None instead of model.zero_grad()
</h1>
<p>
Not this:
</p>
<div id="cb4" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1">model.zero_grad()</a></code></pre>
</div>
<p>
But this!
</p>
<div id="cb5" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="cf">for</span> param <span class="kw">in</span> model.parameters():</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">    param.grad <span class="op">=</span> <span class="va">None</span></a></code></pre>
</div>
<p>
The former executes memset for every parameter in the model, and backward pass updates gradients with “+=” operator (read + write). This is a slow and naive implementation of PyTorch, will hopefully be fixed. The latter doesn’t execute memset for every parameter, memory is zeroed-out by the allocator in a more efficient way and backward pass updates gradients with “=” operator (write).
</p>
<h1 id="disable-debug-apis-for-final-training">
Disable debug APIS for final training
</h1>
<p>
There are many debug APIs that might be enabled, this slows everything down. Here are some: * torch.autograd.detect_anomaly * torch.autograd.set_detect_anomaly(True) * torch.autograd.profiler.profile * torch.autograd.profiler.emit_nvtx * torch.autograd.gradcheck * torch.autograd.gradgradcheck
</p>
<h1 id="use-efficient-multi-gpu-backend">
Use efficient multi-GPU backend
</h1>
<p>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html">DataParalell</a> uses 1 CPU core and 1 python process to drives multiple GPUs. Works for a single node, but even for that <a href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">DistributedDataparallel</a> is often faster. IT provides 1 CPU core for each GPU, likewise 1 python process for each GPU. It can do Single-node and multi-node (same API), has efficient implementation with automatic bucketing for grad all-reduce, all-reduce overlapped with backward pass and is for all intended purposes multi-process programming.
</p>
<h1 id="fuse-pointwise-operations">
Fuse pointwise operations
</h1>
<p>
PyTorch JIT can fuse pointwise operations into a single CUDA kernel. Unfused pointwise operations are memory-bound, for each unfused op PyTorch has to: * launch a separate CUDA kernel * load data from global memory * perform computation * store results back into global memory
</p>
<p>
I.e from this:
</p>
<div id="cb6" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">def</span> gelu(x):</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">    <span class="cf">return</span> x <span class="op">*</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">+</span> torch.erf(x <span class="op">/</span> <span class="fl">1.41421</span>))</a></code></pre>
</div>
<p>
to this:
</p>
<div id="cb7" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="at">@torch.jit.script</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="kw">def</span> fused_gelu(x):</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">    <span class="cf">return</span> x <span class="op">*</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">+</span> torch.erf(x <span class="op">/</span> <span class="fl">1.41421</span>))</a></code></pre>
</div>
<h1 id="construct-tensors-directly-on-gpus">
Construct tensors directly on GPUs
</h1>
<p>
Dont do this:
</p>
<div id="cb8" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1">t <span class="op">=</span> tensor.rand(<span class="dv">2</span>,<span class="dv">2</span>).cuda()</a></code></pre>
</div>
<p>
Instead, create the tensor directly on the device:
</p>
<div id="cb9" class="sourceCode">
<pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" data-line-number="1">t <span class="op">=</span> tensor.rand(<span class="dv">2</span>,<span class="dv">2</span>, device<span class="op">=</span>torch.device(<span class="st">&#39;cuda:0&#39;</span>))</a></code></pre>
</div>
<p>
Its faster!
</p>
<h1 id="summary">
Summary:
</h1>
<ul>
<li>
use async data loading / augmentation
</li>
<li>
enable cuDNN autotuner
</li>
<li>
increase the batch size, disable debug APIs and remove unnecessary computation
</li>
<li>
efficiently zero-out gradients
</li>
<li>
use DistributedDataParallel instead of DataParallel
</li>
<li>
apply PyTorch JIT to fuse pointwise operations
</li>
</ul>


                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2020/09/22/Essay/" data-toggle="tooltip" data-placement="top" title="GPS-independent localization framework for Aerial vehicles">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2020/10/16/Second-Presentation/" data-toggle="tooltip" data-placement="top" title="Second progress presentation">Next Post &rarr;</a>
                    </li>
                    
                </ul>

            </div>
        </div>
    </div>
</article>

<hr>

<div class="container" style="padding-right: 50px;padding-left: 50px;">
<div class="row">
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1" id="disqus_thread">

</div>
</div>
</div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = '';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


<hr>


	
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/gil-uav/">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
									
                </ul>
            </div>
        </div>
    </div>
</footer>



</body>

</html>

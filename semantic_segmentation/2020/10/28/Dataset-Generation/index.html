<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="GPS-Independent Localization for UAVs">
	<meta property="og:title" content="Dataset generation" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gil-uav.github.io////semantic_segmentation/2020/10/28/Dataset-Generation/" />
<meta property="og:image" content="https://gil-uav.github.io///img/home-bg-2.jpg">
	
	

	<meta name="citation_title" content="Project Pages - An Integrated Scientific Blogging Template">


<meta name="citation_author" content="Vegard Bergsvik Øvstegård">



	

	<link rel='shortcut icon' type='image/png' href='/favicon.png' />

    <title>Dataset generation - GIL-UAV</title>

    <link rel="canonical" href="https://gil-uav.github.io//semantic_segmentation/2020/10/28/Dataset-Generation/">
	
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/clean-blog.css">
	
	<!-- Adjust Colors -->
    <link rel="stylesheet" href="https://gil-uav.github.io//colorscheme.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/syntax.css">

    <!-- Custom Fonts -->
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
	<!-- Math Jax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script type="text/javascript"
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		TeX: { equationNumbers: { autoNumber: "AMS" } }
	});
	</script>

	<!--<script src="http://cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3.min.js" type="text/javascript"></script>-->

    <!-- jQuery -->
	<script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>

	<!-- Bootstrap Core JavaScript -->
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

	<!-- Custom Theme JavaScript -->
	<script src="https://gil-uav.github.io//js/clean-blog.min.js "></script>
	
	
<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100795269-2', 'auto');
  ga('send', 'pageview');

</script>

	
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>
</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">GIL-UAV</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
				
                <li>
                    <a href="/projects/semantic_segmentation/">Semantic segmentation</a>
                </li>
                
                
                <li>
                    <a href="/about/">About</a>
                </li>
                
                <li>
                    <a href="/search/">Search</a>
                </li>
                
                <li>
                    <a href="/members/">Members</a>
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/home-bg-2.jpg');">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading" style="padding: 30px 0">
                    <h1>Dataset generation</h1>
                    
                    <h2 class="subheading">Some thoughts and status around the dataset.</h2>
                    
                    <span class="meta">Posted by Vegard Bergsvik Øvstegård on October 28, 2020</span>	
                </div>
            </div>
        </div>
    </div>
</header>






	
	
	
	<div class="float-left">
	<div class="recentpost" style="padding: 10px">
	
	<h4> Recently by the same author: </h4> 
	
	<hr class="style-one">
	
	<a href="/2020/11/12/Third-Presentation/"><h2 class="post-title"> Third progress presentation</h2></a>
	
	
		<h4 class="post-subtitle">Brief presentation of current progress.</h4>
	
	
	<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on November 12, 2020</p>
	
	<div class="notepad-index-post-tags" style="">
	<a href="/search/index.html#presentation" title="Other posts from the Presentation tag">Presentation</a>
	</div> 
	
			
 

<hr class="style-one">

	<img src="/img/profile.jpg" style="margin-top:0px; margin-bottom:5px; margin:auto; width:120px !important; border-radius: 50%;">
	
	<h3>Vegard Bergsvik Øvstegård</h3>
	
	<h4>Master Student at University of Oslo's Department of Informatics</h4>
	
	 
	<a href="https://github.com/vegovs" title="Github"><img src="/img/icons/github-icon.png " style="height:50px; float:right; margin-bot:10px"></a>
	
	
	
	<a href="https://ovstegard.no/" title="Google Plus"><img src="/img/icons/url-icon.png " style="height:33px; float:right; margin-top:9px;  margin-right: 10px"></a>
	
	


	
	</div>
	</div>
	
	
	
	
		
	

<!-- Also Interesting -->



	
	
	

	
	 
	
	
		 
		
		<div class="float-right">
		<div class="relevantpost" style="padding: 10px">
		
		
		<h4> You may find interesting: </h4> 
		
		<hr class="style-one">
		
		<a href="/semantic_segmentation/2020/11/11/Dataset-V2/"><h2 class="post-title"> The dataset v0.1.0</h2></a>
		
		
			<h4 class="post-subtitle">Results from dataset v0.0.1 and a bump to v0.1.0</h4>
		
		
		<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on November 11, 2020</p>
		
		<div class="notepad-index-post-tags" style="">
		<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
		</div> 
		
		
		
		
	
			
		
		 
		
		<hr class="style-one">
		
		<a href="/semantic_segmentation/2020/11/11/Dataset-V2/"><h2 class="post-title"> The dataset v0.1.0</h2></a>
		
		
			<h4 class="post-subtitle">Results from dataset v0.0.1 and a bump to v0.1.0</h4>
		
		
		<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on November 11, 2020</p>
		
		<div class="notepad-index-post-tags" style="">
		<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
		</div> 
		
		
		
		
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
	


		</div>
		</div>

<!-- Post Content -->
<style>
img {
	display:block;
	max-width:  100%;
	margin-left: auto;
	margin-right: auto;
}

@media only screen and (min-width: 1000px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(1.2); 
	-webkit-transform:scale(1.2);
	-o-transform:scale(1.2);
}
}

@media only screen and (min-width: 1250px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(1.5); 
	-webkit-transform:scale(1.5);
	-o-transform:scale(1.5);
}
}

@media only screen and (min-width: 1500px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(2); 
	-webkit-transform:scale(2);
	-o-transform:scale(2);
}
}
</style>

<article>
    <div id="content" class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<h1 id="background">
Background
</h1>
<p>
In machine learning, a data set is a collection of data. In this work, it is a collection of sets of 2 images, <strong>x</strong>, and <strong>y</strong>. Where <strong>x</strong>, the input image, is an <a href="https://www.sciencedirect.com/topics/earth-and-planetary-sciences/orthophoto">orthophoto</a> while the other, <strong>y</strong>, is the ground truth of buildings and other classes.
</p>
<figure>
<img src="/img/set_example.png" alt="Example of a set with x(left) and y(right)" />
<figcaption>
Example of a set with <strong>x</strong>(left) and <strong>y</strong>(right)
</figcaption>
</figure>
<p>
While there are many open-source and publicly available datasets, that contain such sets of images. It is difficult finding datasets that have the specifications needed to train such a network that this work requires. E.g lack of environmental variance, poor resolution, and different labels/ground truth.
</p>
<p>
Therefore, a completely new dataset with the following requirements has to be created:
</p>
<ul>
<li>
Ground truth containing at least buildings.
<ul>
<li>
Water, roads, and other static objects are welcome.
</li>
</ul>
</li>
<li>
Environmental variance such as:
<ul>
<li>
Weather
</li>
<li>
Season
</li>
<li>
Time
</li>
<li>
Location
</li>
</ul>
</li>
<li>
At least 1000 images per, class, weather state, season, time, and location.
</li>
<li>
Good resolution and a low <a href="https://en.wikipedia.org/wiki/Ground_sample_distance">ground sample distance</a>.
</li>
</ul>
<h1 id="getting-the-data">
Getting the data
</h1>
<p>
As a student at the University of Oslo, one can be provided access to some of the data not available to the public at the Norwegian Mapping Authority, <a href="https://www.kartverket.no/">Kartverket</a>. This not only provides vectorized maps working as very good ground truths for buildings and water but also some very decent orthophotos. However, they are all taken at a time when there is little to no occlusion from leaves, snow, etc, and the timing of day to provide the best possible lighting conditions for photography. I.e lacking the environmental variance needed. The aforementioned vectorized maps did also include segmented roads, but only public roads and not drive-ways to private properties as so on. Public roads and private driveways are usually both made of asphalt, and look the same. There is a suspicion that having, say only half the valid data classified as true will cause too much noise during training. None the less a very good starting point, and with tools like <a href="https://qgis.org/en/site/">QGIS</a>, it is possible to apply orthophotos collected elsewhere and maps created using <a href="https://en.wikipedia.org/wiki/Photographic_mosaic">photographic mosaic</a> and a drone.
</p>
<h2 id="ground-sampling-distance-and-field-of-view">
Ground sampling distance and field of view
</h2>
<p>
As the Norwegian Civil Aviation Authority states, the max flight altitude in Norway for uncertified and private drones is a maximum of 120 meters relative to the ground. Given the specifications on a typical drone such as the <a href="https://www.dji.com/no/mavic-2/info">DJI Mavic 2 Pro</a>, this results in a horizontal viewing field of approximately 57m by 32m on a 16:9 aspect ratio, and a Ground Sampling Distance (GSD) 2.95cm:
</p>
<p>
<br /><span class="math display"><br /><span class="math display">$$ GSD_w = \frac{S_w \times H}{F_r \times im_W} = 2.95cm $$</span><br /></span><br />
</p>
<p>
<br /><span class="math display"><br /><span class="math display">$$
\begin{align*}
D_w = GSD \times im_W = 57m
\end{align*}
$$</span><br /></span><br /> <br /><span class="math display"><br /><span class="math display">$$
\begin{align*}
D_h = GSD \times im_H = 32m
\end{align*}
$$</span><br /></span><br />
</p>
<ul>
<li>
<span class="math inline"><em>D</em><sub><em>w</em></sub></span> - Horizontal plane footprint width
</li>
<li>
<span class="math inline"><em>D</em><sub><em>h</em></sub></span> - Horizontal plane footprint height
</li>
<li>
<span class="math inline"><em>S</em><sub><em>w</em></sub> = 13.2</span> - Sensor width(mm)
</li>
<li>
<span class="math inline"><em>H</em> = 120</span> - Height(m)
</li>
<li>
<span class="math inline"><em>F</em><sub><em>r</em></sub> = 28</span> - Focal length(mm)
</li>
<li>
<span class="math inline"><em>i</em><em>m</em><sub><em>W</em></sub> = 1920</span> - Image width(px)
</li>
<li>
<span class="math inline"><em>i</em><em>m</em><sub><em>H</em></sub> = 1080</span> - Image height(px)
</li>
</ul>
<p>
These specifications are somewhat important as they describe what the network will work on and most likely should train on. Ground sampling distance (GSD) is the “real-life” spatial distance between each pixel center. Some orthophotos from Kartverket can be downloaded with a GSD down to 4cm, and with a 4:3 aspect ration on full HD (1440px by 1080px), gives us a GSD of about 3.93. However, with this spatial resolution and an area of 3.2km by 2.4km, it would result in an uncompressed TIFF file of about 14Gb according to Kartverket. As the objective is to segment buildings, it seems that this high-resolution is not necessary. Then again, this work is research and such inquiries must be sought out. Below are two images comparing the GSD of 25cm and 44cm.
</p>
<figure>
<img src="/img/bo25.jpg" alt="GSD = 25cm" />
<figcaption>
GSD = 25cm
</figcaption>
</figure>
<figure>
<img src="/img/bo44.jpg" alt="GSD = 44cm" />
<figcaption>
GSD = 44cm
</figcaption>
</figure>
<p>
Previous work such as Sahu et al. <span class="citation" data-cites="sahu">[1]</span> used GSD as high as 100cm with decent results, on a very similar task as this. On the other hand Horwath et al <span class="citation" data-cites="horwath">[2]</span>. mentions improvements in accuracy for high resolution images in electron microscopy images, but not without challenges. The aforementioned task is although not directly transferable to segmenting buildings, as they were looking for very small particles with a radius of circa 4-6 pixels in a 1024x1024 image. E.g a small shed with a size of <span class="math inline">1<em>m</em><sup>2</sup></span> would take up about 20x20 pixels, and most static buildings are bigger than <span class="math inline">1<em>m</em><sup>2</sup></span>.
</p>
<p>
Another point is that the network will run on a drone with limited computational resources. Floating-point operations are not free and unlimited. For this reason images with a GSD of 20 will suffice as a start, and if need be, access to higher resolution images is possible. As previously mentioned, images captured with a drone might also be added due to the lacking environmental variance that the images from Kartverket have. These will have almost the same GSD calculated above as the drone that will be used is a DJI Mavic Pro.
</p>
<p>
50 Gb of raster maps have been ordered, and the dataset will be adapted and updated continuously until adequate results on real drone photos have been produced by a potential network. With this in mind, the test-set will mostly contain drone footage as this is what the network will process when the framework is in production. The first version of the dataset is hopefully finished by the end of next week. The complete version, however, will not be ready until enough environmental variance is captured, and to no one’s surprise, time nor weather can be controlled.
</p>
<div id="refs" class="references">
<div id="ref-sahu">
<p>
[1] M. Sahu and A. Ohri, “VECTOR MAP GENERATION FROM AERIAL IMAGERY USING DEEP LEARNING,” <em>ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences</em>, vols. IV-2/W5, no. 2/W5, pp. 157–162, May 2019, doi: <a href="https://doi.org/10.5194/isprs-annals-IV-2-W5-157-2019">10.5194/isprs-annals-IV-2-W5-157-2019</a>.
</p>
</div>
<div id="ref-horwath">
<p>
[2] J. P. Horwath, D. N. Zakharov, R. Mégret, and E. A. Stach, “Understanding important features of deep learning models for segmentation of high-resolution transmission electron microscopy images,” <em>npj Computational Materials</em>, vol. 6, no. 1, Dec. 2020, doi: <a href="https://doi.org/10.1038/s41524-020-00363-x">10.1038/s41524-020-00363-x</a>.
</p>
</div>
</div>


                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/semantic_segmentation/2020/10/25/Semantic-Segmentation-Background/" data-toggle="tooltip" data-placement="top" title="Semantic Segmentation Background">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/semantic_segmentation/2020/10/30/Dataset-Generation-Pt2/" data-toggle="tooltip" data-placement="top" title="Dataset generation pt. 2">Next Post &rarr;</a>
                    </li>
                    
                </ul>

            </div>
        </div>
    </div>
</article>

<hr>

<div class="container" style="padding-right: 50px;padding-left: 50px;">
<div class="row">
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1" id="disqus_thread">

</div>
</div>
</div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = '';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


<hr>


	
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/gil-uav/">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
									
                </ul>
            </div>
        </div>
    </div>
</footer>



</body>

</html>

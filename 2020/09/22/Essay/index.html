<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="GPS-Independent Localization for UAVs">
	<meta property="og:title" content="GPS-independent localization framework for Aerial vehicles" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gil-uav.github.io////2020/09/22/Essay/" />
<meta property="og:image" content="https://gil-uav.github.io///img/home-bg-2.jpg">
	
	

	<meta name="citation_title" content="Project Pages - An Integrated Scientific Blogging Template">


<meta name="citation_author" content="Vegard Bergsvik Øvstegård">



	

	<link rel='shortcut icon' type='image/png' href='/favicon.png' />

    <title>GPS-independent localization framework for Aerial vehicles - GIL-UAV</title>

    <link rel="canonical" href="https://gil-uav.github.io//2020/09/22/Essay/">
	
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/clean-blog.css">
	
	<!-- Adjust Colors -->
    <link rel="stylesheet" href="https://gil-uav.github.io//colorscheme.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="https://gil-uav.github.io//css/syntax.css">

    <!-- Custom Fonts -->
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
	<!-- Math Jax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script type="text/javascript"
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		TeX: { equationNumbers: { autoNumber: "AMS" } }
	});
	</script>

	<!--<script src="http://cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3.min.js" type="text/javascript"></script>-->

    <!-- jQuery -->
	<script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>

	<!-- Bootstrap Core JavaScript -->
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

	<!-- Custom Theme JavaScript -->
	<script src="https://gil-uav.github.io//js/clean-blog.min.js "></script>
	
	
<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100795269-2', 'auto');
  ga('send', 'pageview');

</script>

	
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>
</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">GIL-UAV</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
				
                <li>
                    <a href="/projects/mcl/">Monte Carlo Localization</a>
                </li>
                
                <li>
                    <a href="/projects/optimizations/">Optimizations</a>
                </li>
                
                <li>
                    <a href="/projects/semantic_segmentation/">Semantic segmentation</a>
                </li>
                
                
                <li>
                    <a href="/about/">About</a>
                </li>
                
                <li>
                    <a href="/search/">Search</a>
                </li>
                
                <li>
                    <a href="/members/">Members</a>
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/home-bg-2.jpg');">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading" style="padding: 30px 0">
                    <h1>GPS-independent localization framework for Aerial vehicles</h1>
                    
                    <h2 class="subheading">A short Introduction to the framework.</h2>
                    
                    <span class="meta">Posted by Vegard Bergsvik Øvstegård on September 22, 2020</span>	
                </div>
            </div>
        </div>
    </div>
</header>






	
	
	
	<div class="float-left">
	<div class="recentpost" style="padding: 10px">
	
	<h4> Recently by the same author: </h4> 
	
	<hr class="style-one">
	
	<a href="/semantic_segmentation/2020/10/28/Dataset-Generation/"><h2 class="post-title"> Dataset generation</h2></a>
	
	
		<h4 class="post-subtitle">Some thoughts and status around the dataset.</h4>
	
	
	<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on October 28, 2020</p>
	
	<div class="notepad-index-post-tags" style="">
	<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
	</div> 
	
			
 

<hr class="style-one">

	<img src="/img/profile.jpg" style="margin-top:0px; margin-bottom:5px; margin:auto; width:120px !important; border-radius: 50%;">
	
	<h3>Vegard Bergsvik Øvstegård</h3>
	
	<h4>Master Student at University of Oslo's Department of Informatics</h4>
	
	 
	<a href="https://github.com/vegovs" title="Github"><img src="/img/icons/github-icon.png " style="height:50px; float:right; margin-bot:10px"></a>
	
	
	
	<a href="https://ovstegard.no/" title="Google Plus"><img src="/img/icons/url-icon.png " style="height:33px; float:right; margin-top:9px;  margin-right: 10px"></a>
	
	


	
	</div>
	</div>
	
	
	
	
		
	

<!-- Also Interesting -->



	
	
	

	
	 
	
	
		 
		
		<div class="float-right">
		<div class="relevantpost" style="padding: 10px">
		
		
		<h4> You may find interesting: </h4> 
		
		<hr class="style-one">
		
		<a href="/semantic_segmentation/2020/10/25/Semantic-Segmentation-Background/"><h2 class="post-title"> Semantic Segmentation Background</h2></a>
		
		
			<h4 class="post-subtitle">This post contains an overview and description of former work and terminology related to Semantic Segmentation.</h4>
		
		
		<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on October 25, 2020</p>
		
		<div class="notepad-index-post-tags" style="">
		<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
		</div> 
		
		
		
		
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
			
		
	
	
	

	
	 
	
	
			
		
		 
		
		<hr class="style-one">
		
		<a href="/semantic_segmentation/2020/09/23/Pytorch-Optimizations/"><h2 class="post-title"> Pytorch(v>=1.6.0) performance tuning tips</h2></a>
		
		
			<h4 class="post-subtitle">Simple techniques to improve training performance</h4>
		
		
		<p class="post-meta" style="margin-top: 5px;margin-bottom:5px; font-size: 0.8em">Posted by Vegard Bergsvik Øvstegård on September 23, 2020</p>
		
		<div class="notepad-index-post-tags" style="">
		<a href="/search/index.html#post" title="Other posts from the Post tag">Post</a>&nbsp;<a href="/search/index.html#optimizations" title="Other posts from the Optimizations tag">Optimizations</a>&nbsp;<a href="/search/index.html#machine-learning" title="Other posts from the Machine-learning tag">Machine-learning</a>
		</div> 
		
		
		
		
	
	

	
	
	

	
	 
	
	
			
		
			
		
	
	
	


		</div>
		</div>

<!-- Post Content -->
<style>
img {
	display:block;
	max-width:  100%;
	margin-left: auto;
	margin-right: auto;
}

@media only screen and (min-width: 1000px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(1.2); 
	-webkit-transform:scale(1.2);
	-o-transform:scale(1.2);
}
}

@media only screen and (min-width: 1250px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(1.5); 
	-webkit-transform:scale(1.5);
	-o-transform:scale(1.5);
}
}

@media only screen and (min-width: 1500px) {
img {
	-moz-transition:-moz-transform 0.5s ease-in; 
	-webkit-transition:-webkit-transform 0.5s ease-in; 
	-o-transition:-o-transform 0.5s ease-in;
}
img:active{
	-moz-transform:scale(2); 
	-webkit-transform:scale(2);
	-o-transform:scale(2);
}
}
</style>

<article>
    <div id="content" class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<h1 id="introduction">
Introduction
</h1>
<p>
In recent years, the popularity and use of <a href="https://www.sciencedirect.com/topics/engineering/unmanned-aerial-vehicles">Unmanned Aerial Vehicles</a> (UAV) have increased drastically <span class="citation" data-cites="uav-usage">[1]</span>. The usage and potential for both civilian and military applications are plural. From crop dusting and monitoring, infrastructure inspections to surveillance, and accident reporting. Drones have an increasingly larger presence and influence on our lives. With this in mind, it is very important that they and the systems they depend on work as intended.
</p>
<p>
Most classes of robots, in civilian and military applications, localization and navigation are fundamental capabilities. They are especially important for UAVs to execute complex operations. <a href="https://www.sciencedirect.com/topics/engineering/inertial-navigation-system">Inertial Navigation System</a> (INS) and <a href="https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/global-positioning-system">Global Positioning Systems</a> (GPS) are often an integrated and crucial part of a UAV’s navigation systems, despite their weaknesses.
</p>
<p>
State estimation from INS is rarely used alone and mostly aids position estimation when the GPS signal is unavailable or corrupt. However, due to hardware imperfections <span class="citation" data-cites="ins-drift">[2]</span> that are very difficult to avoid, INS will drift over time.
</p>
<p>
Carrol <span class="citation" data-cites="carrol">[3]</span> and Caballero <span class="citation" data-cites="caballero">[4]</span> et al. state that the number of satellites and the quality of their respective signals play an important part in estimating a GPS receivers position. Few satellites or degraded signals will affect the estimation. Many factors affect GPS signals and estimation <span class="citation" data-cites="gps-accuracy">[5]</span>, those most relevant to Aerial Vehicles (AV) are for instance Signal Occlusion (SO). This happens when satellite signals are blocked due to buildings, bridges, trees, or other obstacles. When signals are reflected off buildings or walls, causing <a href="https://www.sciencedirect.com/topics/engineering/multipath-propagation">multipath propagation</a> (MP). <a href="https://www.sciencedirect.com/topics/engineering/jammers">Jamming</a>, <a href="https://www.sciencedirect.com/topics/engineering/radio-interference">Radio interference</a>, or some Atmospheric conditions such as major solar storms can cause issues and corrupt signals. Satellite maintenance or maneuvers creating temporary gaps in coverage are also problematic.
</p>
<p>
As mentioned, UAVs are heavily dependent on GPS for navigation and localization. To obtain a robust positioning system, the many potential errors related to GPS has to be overcome. In recent years, active jamming of GPS signals has been claimed by the Norwegian government <span class="citation" data-cites="gps-jamming">[6]</span>, resulting in a disruption of civilian flights. I.e having a GPS independent localization solution is of high importance and in some situations crucial. This motivates for developing alternate localization methods, able to work both alongside and independent of existing ones. Weight, space, size, and battery capacity are limited resources on UAV’s, i.e there must be a cap on said factors and the upsides of the functionality must outweigh the downsides of the added hardware.
</p>
<p>
In addition to GPS and INS, cameras are a very common sensor embedded on UAV platforms. With the continuing reduction in weight, price, and size compared to <a href="https://www.sciencedirect.com/topics/engineering/light-detection-and-ranging">LIDAR</a> or <a href="https://www.sciencedirect.com/topics/earth-and-planetary-sciences/laser-range-finders">Laser Range Finder</a>, the use of cameras has increased and is often regarded as a standard sensor. As images contain massive amounts of information about the environment, they are useful for many tasks. Vision-based localization systems are one of them and use only one or several embedded cameras on the UAV and a map of the environment. They do not rely on other external systems such as ground stations or satellites. Thus, a camera serves as a good candidate for a redundant localization solution or replacement when GPS fails.
</p>
<p>
Mantelli et al. <span class="citation" data-cites="mantelli">[7]</span> mention a possible approach and its challenges for the vision-based UAV <a href="https://www.sciencedirect.com/topics/engineering/localization-problem">localization problem</a>. Using a downwards facing camera, providing aerial images of the environment, and estimating the position of the images on an <em>a priori</em> known map that is based on aerial or satellite images. Most of the planet is already mapped using the aforementioned methods, there are many free and online sources providing maps like these such as Google™ Earth, Bing ™ Maps, and others. There are also increasingly more areas with detailed topography information from LIDARS and other sensors. Some of the quoted challenges with this problem are the update frequency and resolution of the maps. The images collected by the UAV might also have a significant difference compared to the <em>a priori</em> map. <a href="https://www.sciencedirect.com/topics/engineering/illumination-condition">Illumination conditions</a>, transient ground modifications caused by moving objects, weather conditions in particular rainfall and snow, but also long-term static modifications such as new roads or buildings.
</p>
<p>
Many works propose different types of maps and measurement models to overcome the challenges related to the <a href="https://www.sciencedirect.com/topics/engineering/localization-problem">UAV localization problem</a>. Concerning this problem; maps are often 2D orthogonal maps or 3D point-clouds of the environment, and measurement models are functions that compute the similarity of the UAVs sensory data and a patch of the map. They do however come with caveats, some only work in specific scenarios where robustness falls out, and others have high <a href="https://www.sciencedirect.com/topics/engineering/computational-cost">computational cost</a> or lacking precision. Hence a novel approach to improve such solutions is important to localize the UAV with high robustness and low power usage.
</p>
<p>
This essay proposes a somewhat novel strategy but is inspired by Mantelli et al. <span class="citation" data-cites="mantelli">[7]</span>, Masselli et al. <span class="citation" data-cites="masselli">[8]</span> and Nassar et al. <span class="citation" data-cites="nassar">[9]</span>. A downward-facing camera and a vision-based measurement model are used, and an extra step is added in an attempt to improve robustness and decrease the computational cost. The idea is to include an <a href="https://www.sciencedirect.com/topics/computer-science/image-segmentation">image segmentation</a> network such as U-net <span class="citation" data-cites="unet">[10]</span>, and use a very simple binary image descriptor on the segmented images from the camera and the <em>a priori</em> map. Robustness is induced by training the network to be invariant to some of the aforementioned challenges. E.g it should segment out stationary objects such as buildings despite some illumination conditions, weather, and seasonal changes such as snow. To estimate the UAV pose in 4 degrees of freedoms(DoF), the vision-based localization framework will apply the measurement model in a particle filter approach such as Monte Carlo Localization(MCL) <span class="citation" data-cites="mcl">[11]</span>. In short, a segmented image of the UAV’s view is compared to several random patches on the <em>a priori</em> segmented map, and the measurement model describes their similarity. With enough particles over time, the framework should find one that is similar enough to provide a likely position.
</p>
<figure>
<img src="/img/presentation_1.png" alt="" />
<figcaption>
Global localization is made with comparing the segmented image captured by the UAV, <strong>c)</strong>, with the <em>a priori</em> map representing the ground truth <strong>b)</strong>, describing the environment <strong>a)</strong> with segmenting long-term objects such as buildings and roads.
</figcaption>
</figure>
<p>
As per , the suggested framework compares the image observed and segmented by the robot, c), with a patch from the ground truth, b). As we are passing the observed image through a network, there might be a need to pre-process the observed images. However, as the segmentation reduces the dimensionality of the images, the computational cost of comparing the observed image to a patch is lower. E.g the measurement model compares a few classes and not the different pixel values. This in turn resulting in higher robustness and hopefully lower computational cost. The approach is proposed as a redundant framework to estimate the UAV’s pose. There are nevertheless some situations where the framework will have trouble producing a precise position as when passing over areas with little to no buildings or roads. There might also be errors when flying over homogeneous regions.
</p>
<p>
Prior simulations have shown that a simple binary measurement model used in an MCL approach is highly successful in localizing the UAV’s pose, but this is given a perfect segmentation. However, with the stochastic nature of the MCL approach, a segmentation network of mediocre quality in accuracy and precision with some post-processing might produce decent results in localizing the UAV. Morphological operations such as dilation and erosion combined with shape matching using Hu moments <span class="citation" data-cites="hu">[12]</span> might improve localization as buildings more often than none have somewhat strict geometric shapes. I.e creating squares and rectangles out of the blobs that the network might produce. Nonetheless, the simulation is an indicator that the suggested framework does bear some merit.
</p>
<h1 id="background-and-related-work">
Background and Related work
</h1>
<p>
In recent years, advances in non-GPS <a href="https://www.sciencedirect.com/topics/engineering/localisation">localization</a> of UAVs have been made, showing that this method has promise. While their implementation differs, MCL is often used. Many works propose vision-based solutions to the <a href="https://www.sciencedirect.com/topics/engineering/localization-problem">UAV localization problem</a> using different approaches. They often deal with two different fundamental tasks, global <a href="https://www.sciencedirect.com/topics/engineering/localisation">localization</a> and <a href="https://www.sciencedirect.com/topics/engineering/tracking-position">position tracking</a>. Furthermore, we show some works that use different descriptors for image matching in vision-based solutions, and also different approaches to image segmentation. Both global localization, and position tracking, describe the problem of determining a robot’s pose relative to a given map of the environment. However, the latter knows the robots initial pose, while the former does now.
</p>
<p>
<strong>Global localization:</strong> Masselli et al. <span class="citation" data-cites="masselli">[8]</span> attempt UAV localization with a particle filter and terrain classification through feature extraction. Their solution provides global localization and an average error of <span class="math inline">5.2<em>m</em></span> but is not proven to be robust against all environmental changes, just some lighting, and seasonal changes. We believe that segmentation through Deep Learning will yield a much more accurate result that is more robust against environmental changes. Mantelli et al. <span class="citation" data-cites="mantelli">[7]</span> propose a new localization strategy for a UAV equipped with a downward-facing camera, using a robust vision-based measurement model. The proposed measurement model computes the likelihood of the robot pose with the aid of an improved descriptor called abBRIEF <span class="citation" data-cites="mantelli">[7]</span>, based on BRIEF <span class="citation" data-cites="brief">[13]</span>. The abBRIEF descriptor differs from BRIEF in two points: the color space used and the noise image reduction strategy. Their vision-based localization system applies the new measurement model in a Monte Carlo Localization (MCL) approach <span class="citation" data-cites="mcl">[11]</span> that estimates the UAV pose in 4 degrees of freedom (DoF). In this paper the UAV is located within a short period, outperforming previous measurement models and yielding low errors, but is not proven to be robust against environmental changes like lighting and seasonal changes. We build upon this approach using a much simpler binary descriptor in combination with image segmentation. Viswanathan et al. <span class="citation" data-cites="viswanathan">[14]</span> demonstrate a working implementation of semantic segmentation with a Bayesian localization algorithm for ground vehicles across seasons, successfully localizing in satellite maps from summer, winter, and spring. Inherently, solving the localization problem is much harder for Unmanned Ground Vehicle (UGV) than for UAV, due to the drastic shift in perspective from the ground images to satellite map images. Although this paper also uses segmentation with LIDAR to locate roads. It gives merit to that invariance across seasons can be solved when using semantic segmentation and a particle filter. An important note is that their “winter” environment contained no snow, but this can be included when training the network.
</p>
<p>
<strong>Position tracking:</strong> Nassar et al. <span class="citation" data-cites="nassar">[9]</span> showing successful segmentation of satellite imagery using U-Net, but using a custom Semantic Shape Matching algorithm to establish the location in the satellite map. While the segmentation is largely successful, localization is sub-par and robustness against environmental changes is not proven. This framework also uses SIFT <span class="citation" data-cites="zheng">[15]</span> Registration making the framework more computational heavy, and it does not inherently provide global localization. Surber et al. <span class="citation" data-cites="surber">[16]</span> also presented an approach to localize a UAV locally, using the UAV’s onboard visual-inertial sensor suite to first build a Reference Map of the UAV’s workspace during a piloted reconnaissance flight. In subsequent flights over this area, the proposed framework combines keyframe-based visual-inertial odometry with novel geometric image-based localization, to provide a real-time estimate of the UAV’s pose with respect to the Reference Map paving the way towards completely automating repeated navigation in this workspace. The stability of the system is ensured by decoupling the local visual-inertial odometry from the global registration to the Reference Map, while GPS feeds are used as a weak prior for suggesting loop closures. The proposed framework is shown to outperform GPS localization significantly and diminishes drift effects via global image-based alignment for consistently robust performance.
</p>
<p>
<strong>Descriptors for image matching:</strong> Zheng et al. <span class="citation" data-cites="zheng">[15]</span> proposed an affine and rotation-invariant SIFT feature-based descriptor to perform matches between UAV and satellite images. This descriptor can vary the shape of the patch around a keypoint, becoming a robust descriptor with manageable computational complexity. Calonder et al. <span class="citation" data-cites="brief">[13]</span> propose the use of binary strings as an efficient feature point descriptor, which the authors call BRIEF. We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L2 norm as is usually done.
</p>
<p>
<strong>Segmentation:</strong> Valada et al. <span class="citation" data-cites="valada">[17]</span> use a Deep Convoluted Neural Network with multiple modalities to achieve state-of-the-art performance on datasets with adverse environmental conditions, proving robust and reliable segmentation with acceptable inference time for mobile robotics. A 4.52 km trail through the Freiburg forest was driven autonomously using only the segmented images from the AdapNet with their Convoluted Mixture of Deep Experts (CMoDE), demonstrating the reliability and robustness claimed above.
</p>
<h1 id="proposed-method">
Proposed method
</h1>
<p>
The localization framework consists of two main building blocks:
</p>
<ul>
<li>
<ol type="1">
<li>
A deep learning module is designed to extract certain semantic categories and produce synthetic images representing these categories.
</li>
</ol>
</li>
<li>
<ol start="2" type="1">
<li>
A particle filter is designed for performing localization on said synthetic images.
</li>
</ol>
</li>
</ul>
<p>
The UAV captures an image, the deep learning module segments the image and feeds it into the MCL, which estimates the UAV position based on a segmented <em>a priori</em> known map. To lower the computational cost of the MCL, heading data from either the IMU or a possible Visual odometry system will also be feed into the MCL.
</p>
<figure>
<img src="/img/framework.png" alt="" />
<figcaption>
Flowchart over the proposed framework. Note the segmentation network requires training pre-flight, also to lessen the computational work of the MCL, heading, and possibly height is input from either an IMU, Compass, or Visual odometry.
</figcaption>
</figure>
<p>
The most important advantage that this method hopefully provides over former methods is robustness against weather and environmental changes, of which they do not provide.
</p>
<h2 id="semantic-segmentation">
Semantic segmentation
</h2>
<p>
While MCL for UAVs with the use of satellite images has been proven to work with good results in previous works, the greatest shortcoming has been its lack of robustness against adverse environmental conditions such as differences in seasons, weather, and lighting. While classical digital image processing might improve robustness with regards to lighting conditions, deep learning has the potential to make the MCL robust against most dynamic environmental factors, as it can learn features invariant to environmental changes and output a semantic representation of both satellite images and UAV images.
</p>
<p>
The first consideration for our implementation is U-net <span class="citation" data-cites="unet">[10]</span> as it is state-of-the-art on microscopic photography segmentation, who, like orthophotography, lacks three-dimensional features. Thus, we expect the U-Net to be performant on processed aerial images (<a href="https://www.sciencedirect.com/topics/earth-and-planetary-sciences/orthophoto">orthophotos</a>), as well, though other nets such as AdapNet <span class="citation" data-cites="valada">[17]</span>, has shown to be better at segmenting multi-scale features, which could be important for a greater variance in drone height. There exist many variations of the U-net, with promising results that will also be taken into consideration.
</p>
<h3 id="data-set">
Data set:
</h3>
<p>
While many datasets for semantic segmentation of aerial and satellite images exist, very few contain the environment variances needed for our application. Thus another challenge is to modify or create a completely new dataset with the mentioned variances. As the Norwegian mapping organization, Kartverket provides detailed vectorized maps that can serve as ground truth for the datasets, see , little work remains to create a large and functional dataset. Producing maps of different seasons and weather can easily be done with a drone and image mosaicking. Combining data from several sets will also aid in high variance possibly reducing overfitting and increasing generalization.
</p>
<figure>
<img src="/img/kartverket.png" alt="" />
<figcaption>
Example of Kartverkets vectorized images.
</figcaption>
</figure>
<h2 id="monte-carlo-localization">
Monte Carlo Localization
</h2>
<p>
The proposed framework utilizes segmented images from a downward-facing camera and localizes them in a segmented orthophoto that is used as a global map. Our approach applies an MCL algorithm, to locate the images which will be described in this section. The pixel comparison model has been simulated and provided outstanding results given a perfect segmentation. The model creates a set <span class="math inline"><em>P</em></span> of <span class="math inline"><em>k</em></span> pixels placed on the same location at both the particle and robot images. The intensities of each pixel <span class="math inline"><em>x</em><sub><em>i</em></sub></span> on both images are then compared and given a binary value depending on the pixels being equal or not. E.g if all pixels have the same intensity in both images, there is a high probability of the images being the same or similar depending on the number of pixels compared.
</p>
<figure>
<img src="/img/pp.PNG" alt="" />
<figcaption>
Example of pixel comparison. Here, a set P containing k = 4 pixels.
</figcaption>
</figure>
<h3 id="mcl-overview">
MCL Overview
</h3>
<p>
Given a map of the environment, the goal of the algorithm is for the robot to determine its pose within the environment.
</p>
<p>
At every time <span class="math inline"><em>t</em></span> the algorithm takes as input the previous belief <span class="math inline"><em>X</em><sub><em>t</em> − 1</sub> = {<em>x</em><sub><em>t</em> − 1</sub><sup>[1]</sup>, <em>x</em><sub><em>t</em> − 1</sub><sup>[2]</sup>, …, <em>x</em><sub><em>t</em> − 1</sub><sup>[<em>M</em>]</sup>}</span>, an actuation command <span class="math inline"><em>u</em><sub><em>t</em></sub></span>, and data received from sensors <span class="math inline"><em>z</em><sub><em>t</em></sub>;</span> and the algorithm outputs the new belief <span class="math inline"><em>X</em><sub><em>t</em></sub></span>. <span class="citation" data-cites="mclalg">[18]</span>
</p>
<figure>
<img src="/img/mcl.png" alt="" />
<figcaption>
MCL algorithm
</figcaption>
</figure>
<h2 id="optimizations-and-hardware">
Optimizations and hardware
</h2>
<p>
The variables and data used in the MCL algorithm and the measurement model, are inherently vectorized. With this in mind, optimizing the code execution to utilize heterogeneous multicore architectures may have a tremendous positive impact on execution time.
</p>
<p>
A development board such as nVIDIA’s Jetson Xavier is a very good candidate for this framework. It provides an ARM-based processor and 8 Volta streaming multiprocessors and consumes a total of 15 Watt at max power draw. The unit is proven to be very efficient in AI usage as it also has 64 Tensor Cores.
</p>
<h1 id="summary-and-future-work">
Summary and future work
</h1>
<p>
The proposed method, if it produces viable results, will provide global localizations in situations where former work has not been successful. The first step is to implement a raw version of the proposed method, see , and eventually optimize the solution on hardware if results are applicable. The most challenging and important part of the method is to provide a tolerable segmentation network, hence this is where most of the early work will reside.
</p>
<h1 class="unnumbered" id="references">
References
</h1>
<div id="refs" class="references" role="doc-bibliography" role="doc-bibliography">
<div id="ref-uav-usage">
<p>
[1] T. Murfin, “UAV Report: Growth Trends &amp; Opportunities for 2019.” https://www.gpsworld.com/uav-report-growth-trends-opportunities-for-2019/, 2018, [Online]. Available: <a href="https://www.gpsworld.com/uav-report-growth-trends-opportunities-for-2019/">https://www.gpsworld.com/uav-report-growth-trends-opportunities-for-2019/</a>.
</p>
</div>
<div id="ref-ins-drift">
<p>
[2] “INS drift.” $$url{https://www.skybrary.aero/index.php/Inertial_Navigation_System_(INS)}.
</p>
</div>
<div id="ref-carrol">
<p>
[3] J. V. Carroll, “Vulnerability assessment of the U.S. transportation infrastructure that relies on the global positioning system,” <em>Journal of Navigation</em>, vol. 56, no. 2, pp. 185–193, 2003, doi: <a href="https://doi.org/10.1017/S0373463303002273">10.1017/S0373463303002273</a>.
</p>
</div>
<div id="ref-caballero">
<p>
[4] F. Caballero, L. Merino, J. Ferruz, and A. Ollero, “Improving vision-based planar motion estimation for unmanned aerial vehicles through online mosaicing,” in <em>Proceedings - ieee international conference on robotics and automation</em>, 2006, vol. 2006, pp. 2860–2865, doi: <a href="https://doi.org/10.1109/ROBOT.2006.1642135">10.1109/ROBOT.2006.1642135</a>.
</p>
</div>
<div id="ref-gps-accuracy">
<p>
[5] US Air Force, “GPS Accuracy.” https://www.gps.gov/systems/gps/performance/accuracy/, 2017, [Online]. Available: <a href="https://www.gps.gov/systems/gps/performance/accuracy/">https://www.gps.gov/systems/gps/performance/accuracy/</a>.
</p>
</div>
<div id="ref-gps-jamming">
<p>
[6] G. O’Dwyer, “Norway says it proved Russian GPS interference during NATO exercises.” https://www.defensenews.com/global/europe/2019/03/08/norway-alleges-signals-jamming-of-its-military-systems-by-russia/.
</p>
</div>
<div id="ref-mantelli">
<p>
[7] M. Mantelli <em>et al.</em>, “A novel measurement model based on abBRIEF for global localization of a UAV over satellite images,” <em>Robotics and Autonomous Systems</em>, vol. 112, pp. 304–319, 2019, doi: <a href="https://doi.org/10.1016/j.robot.2018.12.006">10.1016/j.robot.2018.12.006</a>.
</p>
</div>
<div id="ref-masselli">
<p>
[8] A. Masselli, R. Hanten, and A. Zell, “Localization of unmanned aerial vehicles using Terrain classification from aerial images,” in <em>Advances in intelligent systems and computing</em>, 2015, vol. 302, pp. 831–842, doi: <a href="https://doi.org/10.1007/978-3-319-08338-4_60">10.1007/978-3-319-08338-4_60</a>.
</p>
</div>
<div id="ref-nassar">
<p>
[9] A. Nassar, K. Amer, R. Elhakim, and M. Elhelw, “A deep CNN-based framework for enhanced aerial imagery registration with applications to UAV geolocalization,” in <em>IEEE computer society conference on computer vision and pattern recognition workshops</em>, 2018, vols. 2018-June, pp. 1594–1604, doi: <a href="https://doi.org/10.1109/CVPRW.2018.00201">10.1109/CVPRW.2018.00201</a>.
</p>
</div>
<div id="ref-unet">
<p>
[10] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in <em>Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics)</em>, 2015, vol. 9351, pp. 234–241, doi: <a href="https://doi.org/10.1007/978-3-319-24574-4_28">10.1007/978-3-319-24574-4_28</a>.
</p>
</div>
<div id="ref-mcl">
<p>
[11] J. Ginés, F. Martín, V. Matellán, F. J. Lera, and J. Balsa, “3D Mapping for a Reliable Long-Term Navigation,” in <em>Advances in intelligent systems and computing</em>, 2018, vol. 694, pp. 283–294, doi: <a href="https://doi.org/10.1007/978-3-319-70836-2_24">10.1007/978-3-319-70836-2_24</a>.
</p>
</div>
<div id="ref-hu">
<p>
[12] M. K. Hu, “Visual Pattern Recognition by Moment Invariants,” <em>IRE Transactions on Information Theory</em>, vol. 8, no. 2, pp. 179–187, 1962, doi: <a href="https://doi.org/10.1109/TIT.1962.1057692">10.1109/TIT.1962.1057692</a>.
</p>
</div>
<div id="ref-brief">
<p>
[13] M. Calonder, V. Lepetit, C. Strecha, and P. Fua, “BRIEF: Binary robust independent elementary features,” in <em>Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics)</em>, 2010, vol. 6314 LNCS, pp. 778–792, doi: <a href="https://doi.org/10.1007/978-3-642-15561-1_56">10.1007/978-3-642-15561-1_56</a>.
</p>
</div>
<div id="ref-viswanathan">
<p>
[14] A. Viswanathan, B. R. Pires, and D. Huber, “Vision-based robot localization across seasons and in remote locations,” in <em>Proceedings - ieee international conference on robotics and automation</em>, 2016, vols. 2016-June, pp. 4815–4821, doi: <a href="https://doi.org/10.1109/ICRA.2016.7487685">10.1109/ICRA.2016.7487685</a>.
</p>
</div>
<div id="ref-zheng">
<p>
[15] M. Zheng, C. Wu, D. Chen, and Z. Meng, “Rotation and affine-invariant SIFT descriptor for matching UAV images with satellite images,” in <em>2014 ieee chinese guidance, navigation and control conference, cgncc 2014</em>, 2015, pp. 2624–2628, doi: <a href="https://doi.org/10.1109/CGNCC.2014.7007582">10.1109/CGNCC.2014.7007582</a>.
</p>
</div>
<div id="ref-surber">
<p>
[16] J. Surber, L. Teixeira, and M. Chli, “Robust visual-inertial localization with weak GPS priors for repetitive UAV flights,” in <em>Proceedings - ieee international conference on robotics and automation</em>, 2017, pp. 6300–6306, doi: <a href="https://doi.org/10.1109/ICRA.2017.7989745">10.1109/ICRA.2017.7989745</a>.
</p>
</div>
<div id="ref-valada">
<p>
[17] A. Valada, J. Vertens, A. Dhall, and W. Burgard, “AdapNet: Adaptive semantic segmentation in adverse environmental conditions,” in <em>Proceedings - ieee international conference on robotics and automation</em>, 2017, pp. 4644–4651, doi: <a href="https://doi.org/10.1109/ICRA.2017.7989540">10.1109/ICRA.2017.7989540</a>.
</p>
</div>
<div id="ref-mclalg">
<p>
[18] S. Thrun, “Probabilistic robotics,” <em>Communications of the ACM</em>, vol. 45, no. 3, pp. 52–57, 2002, doi: <a href="https://doi.org/10.1145/504729.504754">10.1145/504729.504754</a>.
</p>
</div>
</div>


                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2020/09/15/First-Presentation/" data-toggle="tooltip" data-placement="top" title="First progress presentation">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/semantic_segmentation/2020/09/23/Pytorch-Optimizations/" data-toggle="tooltip" data-placement="top" title="Pytorch(v>=1.6.0) performance tuning tips">Next Post &rarr;</a>
                    </li>
                    
                </ul>

            </div>
        </div>
    </div>
</article>

<hr>

<div class="container" style="padding-right: 50px;padding-left: 50px;">
<div class="row">
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1" id="disqus_thread">

</div>
</div>
</div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = '';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


<hr>


	
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/gil-uav/">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
									
                </ul>
            </div>
        </div>
    </div>
</footer>



</body>

</html>
